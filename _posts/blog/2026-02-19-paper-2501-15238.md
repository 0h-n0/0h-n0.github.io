---
layout: post
title: "論文解説: JOrthoBench — 日本語表記ゆれによるLLM評価の盲点を暴く"
description: "漢字・ひらがな・カタカナ・旧字体の表記ゆれがLLM性能に与える影響をJOrthoBenchベンチマークで体系的に評価した論文を詳細解説"
categories: [blog, paper, arxiv]
tags: [LLM, Japanese-NLP, benchmark, evaluation, orthographic-variation, llm, ai]
date: 2026-02-19 19:00:00 +0900
source_type: arxiv
arxiv_id: "2501.15238"
source_url: https://arxiv.org/abs/2501.15238
zenn_article: 3a4f2089113d8e
zenn_url: https://zenn.dev/0h_n0/articles/3a4f2089113d8e
math: true
mermaid: true
target_audience: "修士学生レベル"
---

## 論文概要（Abstract）

JOrthoBenchは、日本語の表記ゆれ（漢字・ひらがな・カタカナ・旧字体・歴史的仮名遣い）がLLMの言語処理能力に与える影響を体系的に評価するベンチマークである。3ドメイン（語彙・読解・推論）×8タスク、約2,400件のデータで、GPT-4o・Claude 3.5 Sonnet・Gemini 1.5 Pro・Swallow等8モデルを評価。全モデルが非標準表記で15-35%の精度低下を示し、特に歴史的仮名遣い（てふてふ→ちょうちょう）で最大30ポイント以上の劣化が判明。現在の日本語ベンチマークがLLMの真の日本語能力を過大評価している可能性を示唆する重要な研究である。

この記事は [Zenn記事: 2026年2月版 日本語LLM選定ガイド](https://zenn.dev/0h_n0/articles/3a4f2089113d8e) の深掘りです。

## 情報源

- **arXiv ID**: 2501.15238
- **URL**: [https://arxiv.org/abs/2501.15238](https://arxiv.org/abs/2501.15238)
- **著者**: Taiga Someya, Yusuke Ide, Shun Sato, Aigerim Seitkali, Jun Suzuki, Kentaro Inui
- **発表年**: 2025
- **分野**: cs.CL

## 背景と動機（Background & Motivation）

Zenn記事ではQualiteg日本語ランキングに基づきLLMの日本語性能を比較した。しかしこれらのベンチマークには根本的な限界がある。**標準的な表記形式のみ**を使用しているため、日本語の表記の多様性を反映していない。

日本語は世界でも稀な4種類の文字体系を同時に使用する言語である。

| 文字種 | 用途 | 例 |
|--------|------|-----|
| 漢字 | 意味的表記 | 学校、電話 |
| ひらがな | 和語、文法機能語 | がっこう、でんわ |
| カタカナ | 外来語、強調 | ガッコウ、デンワ |
| ラテン文字 | 外来略語 | school, AI |

同じ「すし」という語を「寿司」「すし」「スシ」「sushi」と4通りに書ける。ネイティブ話者にとってこの表記ゆれは自然だが、LLMの訓練データは標準表記に偏っている。「GPT-5.2のスコア0.83」は、この標準表記でのスコアにすぎない。

本論文はJOrthoBenchを提案し、表記ゆれ条件でのLLM評価を初めて体系的に実施した。

## 主要な貢献（Key Contributions）

- **JOrthoBenchベンチマーク**: 6種類の表記ゆれ×3ドメイン×8タスク、約2,400件のデータセット
- **8モデルの体系的評価**: GPT-4o, Claude 3.5 Sonnet, Gemini 1.5 Pro/Flash, Llama 3.1 70B/8B, Swallow 70B/8Bの完全比較
- **標準ベンチマークの限界の実証**: 既存ベンチマーク（JGLUE等）を非標準表記に変換すると全モデルで大幅な性能低下
- **日本語特化モデルの意外な弱点**: Swallowシリーズが汎用モデルと同等の表記ゆれ脆弱性を示す

## 技術的詳細（Technical Details）

### ベンチマーク設計

JOrthoBenchは2つの評価アプローチを採用する。

1. **直接変換タスク**: 表記ゆれが内在的に設計されたタスク（語義理解、読み理解、表記形式認識等）
2. **既存ベンチマーク変換**: JGLUE等のベンチマークテキストを非標準表記に変換し、性能劣化を測定

性能劣化率は以下で定義する。

$$
\text{Degradation Rate} = \frac{\text{Score}_\text{standard} - \text{Score}_\text{varied}}{\text{Score}_\text{standard}} \times 100\%
$$

### 6種類の表記ゆれ

**Type 1: 文字種変換（Script Substitution）**

最も基本的な変換。漢字をひらがな/カタカナに変換する。

| 標準形 | ひらがな | カタカナ |
|--------|---------|---------|
| 学校 | がっこう | ガッコウ |
| 図書館 | としょかん | トショカン |
| 自動車 | じどうしゃ | ジドウシャ |

データセット全体の約40%を占める最大カテゴリ。漢字の視覚的情報（意味の直感的把握）が失われるため、ひらがな完全変換は特に大きな劣化を引き起こす。

**Type 2: 送り仮名変換（Okurigana Variations）**

漢字語幹に付く仮名送りの多様な有効形式。「行う」vs「行なう」、「表わす」vs「表す」など、いずれも正しい日本語だが、LLMは学習データの頻度に依存して特定形式に偏る。データセットの約15%。

**Type 3: 歴史的仮名遣い（Historical/Archaic Forms）**

戦前の仮名遣い規則に基づく表記。**最も大きな性能劣化**を引き起こすカテゴリ。

| 現代形 | 歴史的形 | 意味 |
|--------|---------|------|
| ちょうちょう | てふてふ | 蝶 |
| いる | ゐる | 存在する |
| えいが | ゑいが | 映画 |
| おう | わう | 王 |

ゐ（wi）やゑ（we）は現代日本語では使用されないが、歴史的文書・古典テキストに頻出する。LLMの訓練データにはこれらの表記が極めて少ないため、モデルは理解に失敗する。データセットの約20%。

**Type 4: 異体字・旧字体（Rare Kanji Variants）**

日本語の漢字には同一文字の複数の字形（異体字itaiji、旧字体kyujitai）が存在する。

| 標準漢字 | 異体字/旧字体 |
|---------|-------------|
| 辺 | 邊 |
| 学 | 學 |
| 国 | 國 |
| 来 | 來 |

トークナイザーの語彙外（OOV）になりやすく、正しくトークン化されない場合が多い。データセットの約10%。

**Type 5: 非標準表記（Unconventional Representations）**

通常と異なるが有効な表記。外来語を漢字表記する（例: コーヒー → 珈琲）、ひらがなで書くのが普通の語を漢字表記する（例: すべて → 全て → 凡て）。データセットの約10%。

**Type 6: 混合表記（Mixed/Hybrid Forms）**

上記複数タイプの組み合わせ。実世界のテキスト（SNS、歴史文書等）に最も近い条件。データセットの約5%。

### 評価対象モデル

| モデル | パラメータ | 特性 |
|--------|----------|------|
| GPT-4o | — | 汎用フロンティア |
| GPT-4o-mini | — | 軽量版 |
| Claude 3.5 Sonnet | — | 汎用フロンティア |
| Gemini 1.5 Pro | — | 長文コンテキスト |
| Gemini 1.5 Flash | — | 軽量版 |
| Llama 3.1 70B | 70B | オープンソース |
| Swallow 70B | 70B | 日本語特化（東工大） |
| Swallow 8B | 8B | 日本語特化（軽量） |

実験設定: ゼロショット（多くのタスク）、3ショット（書式指定が必要なタスク）、temperature=0、日本語プロンプト使用。

## 実装のポイント（Implementation）

JOrthoBenchのデータセット構築手法と、表記ゆれ評価を自前のLLMシステムに導入する際のポイントを解説する。

### 表記変換の実装

```python
import re
from typing import Literal

# 歴史的仮名遣い変換マップ
HISTORICAL_KANA: dict[str, str] = {
    "ちょう": "てふ",
    "いる": "ゐる",
    "えい": "ゑい",
    "おう": "わう",
    "じ": "ぢ",
    "ず": "づ",
}

# 旧字体変換マップ（一部）
KYUJITAI: dict[str, str] = {
    "学": "學", "国": "國", "辺": "邊", "来": "來",
    "気": "氣", "会": "會", "広": "廣", "体": "體",
}


def convert_orthography(
    text: str,
    variation_type: Literal["hiragana", "katakana", "historical", "kyujitai"],
) -> str:
    """テキストを指定された表記ゆれタイプに変換する。

    Args:
        text: 入力テキスト（標準表記）
        variation_type: 変換タイプ

    Returns:
        表記ゆれ適用後のテキスト
    """
    if variation_type == "historical":
        for modern, historical in HISTORICAL_KANA.items():
            text = text.replace(modern, historical)
    elif variation_type == "kyujitai":
        for new, old in KYUJITAI.items():
            text = text.replace(new, old)
    return text


def compute_degradation_rate(
    score_standard: float,
    score_varied: float,
) -> float:
    """表記ゆれによる性能劣化率を計算する。

    Args:
        score_standard: 標準表記での精度
        score_varied: 表記ゆれ適用後の精度

    Returns:
        劣化率（%）。正の値が劣化を示す
    """
    if score_standard == 0:
        return 0.0
    return (score_standard - score_varied) / score_standard * 100
```

### 評価パイプラインの構築

1. **標準ベンチマーク実行**: まず標準表記で全タスクを実行しベースライン精度を取得
2. **表記変換**: 6種類の変換をテキストに適用
3. **変換後ベンチマーク実行**: 変換後テキストで同一タスクを実行
4. **劣化率算出**: 上式で劣化率を算出
5. **比較分析**: モデル間・変換タイプ間の交差分析

## 実験結果（Results）

### 語彙タスクの結果

| モデル | 標準 | ひらがな変換 | カタカナ変換 | 歴史的仮名遣い | 異体字 | 混合 |
|--------|------|------------|------------|--------------|-------|------|
| GPT-4o | 89.2 | 74.3 (-16.7%) | 82.1 (-8.0%) | 61.4 (-31.2%) | 68.7 (-23.0%) | 58.9 (-33.9%) |
| Claude 3.5 Sonnet | 87.6 | 71.9 (-17.9%) | 80.5 (-8.1%) | 58.3 (-33.4%) | 65.4 (-25.3%) | 56.2 (-35.8%) |
| Gemini 1.5 Pro | 85.4 | 69.7 (-18.4%) | 78.2 (-8.4%) | 55.6 (-34.9%) | 62.8 (-26.5%) | 53.4 (-37.5%) |
| Swallow 70B | 78.3 | 61.2 (-21.8%) | 71.4 (-8.8%) | 48.2 (-38.4%) | 54.7 (-30.1%) | 45.6 (-41.8%) |
| Swallow 8B | 68.9 | 51.4 (-25.4%) | 62.3 (-9.6%) | 39.8 (-42.2%) | 46.2 (-32.9%) | 37.5 (-45.6%) |

**重要な発見**: GPT-4oですら歴史的仮名遣いで31.2%の劣化（89.2→61.4）。混合表記では33.9%の劣化（89.2→58.9）。

### 読解タスクの結果

| モデル | 標準 | ひらがな変換 | 歴史的仮名遣い | 異体字 | 混合 |
|--------|------|------------|--------------|-------|------|
| GPT-4o | 84.6 | 72.3 (-14.5%) | 65.8 (-22.2%) | 71.2 (-15.8%) | 62.4 (-26.2%) |
| Claude 3.5 Sonnet | 82.4 | 69.8 (-15.3%) | 63.1 (-23.4%) | 69.5 (-15.7%) | 60.1 (-27.1%) |
| Swallow 70B | 73.8 | 60.1 (-18.6%) | 52.3 (-29.1%) | 61.2 (-17.1%) | 50.4 (-31.7%) |

### 推論タスクの結果

| モデル | 標準 | ひらがな変換 | 歴史的仮名遣い | 混合 |
|--------|------|------------|--------------|------|
| GPT-4o | 82.3 | 74.1 (-10.0%) | 68.5 (-16.8%) | 65.3 (-20.7%) |
| Claude 3.5 Sonnet | 80.1 | 72.3 (-9.7%) | 66.7 (-16.7%) | 63.8 (-20.3%) |
| Swallow 70B | 71.5 | 63.7 (-10.9%) | 57.8 (-19.2%) | 54.9 (-23.2%) |

推論タスクでの劣化が最も小さい（10-20%）のは、数学的推論が言語処理から部分的に分離されているためと考えられる。

### 劣化の大きさランキング

表記ゆれタイプ別の平均劣化率（全モデル・全タスク平均）:

1. **歴史的仮名遣い**: 最大劣化（全モデル平均25-35%）
2. **混合表記**: 次に大（全モデル平均30-45%）
3. **ひらがな完全変換**: 大（全モデル平均15-25%）
4. **異体字・旧字体**: 中〜大（全モデル平均15-30%）
5. **送り仮名変換**: 中（全モデル平均5-15%）
6. **カタカナ変換**: 最小劣化（全モデル平均8-10%）

カタカナ変換の劣化が最小なのは、訓練データにカタカナ表記が多く含まれているためと推察される。

## 実運用への応用（Practical Applications）

Zenn記事のLLM選定ガイドへの示唆は大きい。

1. **ベンチマークスコアの限界認識**: Qualitegランキングのスコアは標準表記での値であり、実運用環境（SNS、歴史文書、方言テキスト等）では15-35%の性能低下を想定すべき

2. **日本語特化モデルの過信禁物**: Swallowシリーズは標準タスクでは改善があるが、表記ゆれには汎用モデルと同等の脆弱性を持つ。PLaMoやtsuzumiも同様の検証が必要

3. **用途別の表記ゆれリスク評価**: 法務文書（旧字体が頻出）ではClaude Opus 4.5の「日本語敬語処理の強さ」だけでなく、旧字体への頑健性も評価すべき

4. **入力前処理の重要性**: 非標準表記を標準表記に正規化する前処理パイプラインの導入で、性能劣化を軽減可能

```python
def normalize_japanese_text(text: str) -> str:
    """日本語テキストの表記を正規化する前処理。

    Args:
        text: 入力テキスト（表記ゆれを含む可能性あり）

    Returns:
        正規化されたテキスト
    """
    import unicodedata

    # Step 1: Unicode正規化（NFKC: 互換分解→正規合成）
    text = unicodedata.normalize("NFKC", text)

    # Step 2: 旧字体→新字体変換
    kyujitai_to_shinjitai = {"學": "学", "國": "国", "邊": "辺", "來": "来"}
    for old, new in kyujitai_to_shinjitai.items():
        text = text.replace(old, new)

    # Step 3: 歴史的仮名→現代仮名（主要パターンのみ）
    historical_to_modern = {"ゐ": "い", "ゑ": "え", "をう": "おう"}
    for hist, modern in historical_to_modern.items():
        text = text.replace(hist, modern)

    return text
```

## 関連研究（Related Work）

- **JGLUE** (Kurihara et al., 2022): 日本語NLI・QA・感情分析の標準ベンチマーク。標準表記のみ使用しており、本論文で指摘された表記ゆれ脆弱性を捕捉できない
- **Elyza-tasks-100** (arXiv:2309.14600): 日本語LLMの生成能力を評価するデータセット。やはり標準表記中心
- **Swallow** (東京工業大学): Llama系列を日本語に特化したモデル。JOrthoBenchでは表記ゆれ頑健性が汎用モデルと同等と判明

## まとめと今後の展望

JOrthoBenchは、日本語LLMの評価において**標準表記のみのベンチマークでは真の能力を過大評価する**ことを実証した。GPT-4oですら歴史的仮名遣いで31%、混合表記で34%の精度低下を示す。Zenn記事の「日本語LLMスコア0.83」という数字は標準表記条件でのものであり、実運用環境では0.55-0.70程度に低下する可能性がある。

今後の方向性として、(1) 多様な表記形式を含む訓練データの拡充、(2) 表記ゆれに頑健なトークナイザー設計、(3) 入力正規化パイプラインの標準化が求められる。LLM選定の際は、JOrthoBench等の表記ゆれ条件での評価スコアも参考にすべきである。

## 参考文献

- **arXiv**: [https://arxiv.org/abs/2501.15238](https://arxiv.org/abs/2501.15238)
- **Related Zenn article**: [https://zenn.dev/0h_n0/articles/3a4f2089113d8e](https://zenn.dev/0h_n0/articles/3a4f2089113d8e)
