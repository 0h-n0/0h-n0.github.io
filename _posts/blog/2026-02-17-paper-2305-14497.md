---
layout: post
title: "論文解説: ChatDev - チャットベース協調によるソフトウェア開発マルチエージェントシステム"
description: "ChatDevのフェーズベースオーケストレーションとChat Chain機構を詳細解説。LLMエージェントが設計・実装・テスト・文書化の全工程を自律的に遂行する仕組みを深掘りする"
categories: [blog, paper, arxiv]
tags: [multi-agent, software-development, chat-chain, orchestration, claude, ai, agent, productivity]
date: 2026-02-17 09:00:00 +0900
source_type: arxiv
arxiv_id: "2307.07924"
source_url: https://arxiv.org/abs/2307.07924
zenn_article: c01f4e292ff1a7
zenn_url: https://zenn.dev/0h_n0/articles/c01f4e292ff1a7
math: true
mermaid: true
target_audience: "修士学生レベル"
---

## 論文概要（Abstract）

ChatDevは、LLM駆動の専門エージェント群がチャットベースの協調を通じてソフトウェア開発を遂行するフレームワークである。設計（Design）、コーディング（Coding）、テスト（Testing）、文書化（Documentation）の4フェーズで構成されるChat Chain機構により、各フェーズでInstructor-Assistantペアの対話を通じてタスクが段階的に完了する。自然言語をエージェント間の統一的なコミュニケーション手段として活用し、従来のフェーズ別深層学習モデルを不要にした点が大きな貢献である。ACL 2024に採択されている。

この記事は [Zenn記事: Claude Octopus: 複数AIを並列実行するオーケストレーションプラグイン](https://zenn.dev/0h_n0/articles/c01f4e292ff1a7) の深掘りです。

## 情報源

- **arXiv ID**: 2307.07924
- **URL**: https://arxiv.org/abs/2307.07924
- **著者**: Chen Qian, Wei Liu, Zhiyuan Liu, Maosong Sun et al.（清華大学）
- **発表年**: 2023（ACL 2024採択）
- **分野**: cs.SE, cs.CL, cs.AI

## 背景と動機（Background & Motivation）

ソフトウェア開発は本質的にマルチフェーズのプロセスであり、設計・実装・テスト・文書化の各段階で異なる専門性が要求される。従来のAIによるコード生成アプローチは、主にコーディングフェーズに焦点を当てており、ソフトウェア開発のライフサイクル全体をカバーしていなかった。

一方、各フェーズに個別の深層学習モデルを配置するアプローチは、モデル間のインターフェース設計が煩雑であり、フェーズ間の情報伝達にロスが生じる。ChatDevは「自然言語はシステム設計に有利であり、プログラミング言語での対話はデバッグに有効」という知見に基づき、言語を統一的なコミュニケーション手段として活用することで、この問題を解決する。

## 主要な貢献（Key Contributions）

- **Chat Chain機構**: ソフトウェア開発をフェーズに分解し、各フェーズをInstructor-Assistantの対話として実行する構造化された会話チェーン
- **Communicative Dehallucination**: エージェント間の対話を通じてLLMの幻覚を相互に検出・修正する手法
- **統一言語コミュニケーション**: 自然言語とプログラミング言語を統一的に扱い、フェーズ別専用モデルを不要にした設計
- **仮想ソフトウェア会社モデル**: CEO、CTO、プログラマー、テスター等の役割を持つエージェントが組織的に協調する枠組み

## 技術的詳細（Technical Details）

### Chat Chain機構

Chat Chainはソフトウェア開発プロセスをフェーズの連鎖として構造化する。各フェーズ$p_i$はInstructor $I_i$とAssistant $A_i$のペアによる対話$D_i$で構成される。

$$
\text{ChatChain} = \{(p_1, D_1), (p_2, D_2), ..., (p_n, D_n)\}
$$

各フェーズの対話は以下のプロセスで進行する：

$$
D_i = \{(m_1^I, m_1^A), (m_2^I, m_2^A), ..., (m_T^I, m_T^A)\}
$$

ここで、
- $p_i$: 第$i$フェーズ（Design, Coding, Testing, Documentation）
- $D_i$: フェーズ$i$における対話セッション
- $m_t^I$: ターン$t$でのInstructorのメッセージ
- $m_t^A$: ターン$t$でのAssistantの応答
- $T$: 対話のターン数上限

前段フェーズの出力$o_{i-1}$が次段フェーズの入力コンテキストとなる：

$$
o_i = f_{\text{phase}}(p_i, D_i, o_{i-1})
$$

### フェーズ構成

**Design Phase（設計）**: CEOがInstructor、CTOがAssistantとなり、ユーザー要件からシステム設計を策定する。出力はモダリティ選択（CLI/GUI/Web）と技術スタック。

**Coding Phase（実装）**: CTOがInstructor、ProgrammerがAssistantとなり、設計に基づいてコードを生成する。出力は実行可能なソースコード。

**Testing Phase（テスト）**: ProgrammerがInstructor、TesterがAssistantとなり、コードレビューとバグ修正を実行する。反復的な修正ループが特徴的。

**Documentation Phase（文書化）**: CEOがInstructor、CPOがAssistantとなり、ユーザーマニュアルを生成する。

### アルゴリズム

```python
from dataclasses import dataclass
from enum import Enum

class Role(Enum):
    """エージェントの役割定義"""
    CEO = "CEO"
    CTO = "CTO"
    PROGRAMMER = "Programmer"
    TESTER = "Tester"
    CPO = "CPO"

@dataclass
class Phase:
    """Chat Chainの1フェーズを表す

    Attributes:
        name: フェーズ名
        instructor: Instructorの役割
        assistant: Assistantの役割
        max_turns: 最大対話ターン数
    """
    name: str
    instructor: Role
    assistant: Role
    max_turns: int = 10


def execute_chat_chain(
    phases: list[Phase],
    user_requirement: str,
    llm_config: dict[str, str],
) -> dict[str, str]:
    """Chat Chainを実行してソフトウェアを生成する

    Args:
        phases: フェーズ定義のリスト
        user_requirement: ユーザーの要件記述
        llm_config: LLM設定

    Returns:
        各フェーズの出力を格納した辞書
    """
    context: str = user_requirement
    outputs: dict[str, str] = {}

    for phase in phases:
        phase_output = _execute_phase(
            phase=phase,
            context=context,
            llm_config=llm_config,
        )
        outputs[phase.name] = phase_output
        context = f"{context}\n\n[{phase.name} Output]:\n{phase_output}"

    return outputs


def _execute_phase(
    phase: Phase,
    context: str,
    llm_config: dict[str, str],
) -> str:
    """1つのフェーズを実行する（擬似実装）

    Args:
        phase: フェーズ定義
        context: 前段フェーズまでの累積コンテキスト
        llm_config: LLM設定

    Returns:
        フェーズの出力文字列
    """
    raise NotImplementedError("Phase execution requires LLM integration")


# Chat Chainの定義
STANDARD_CHAIN: list[Phase] = [
    Phase("Design", Role.CEO, Role.CTO, max_turns=5),
    Phase("Coding", Role.CTO, Role.PROGRAMMER, max_turns=15),
    Phase("Testing", Role.PROGRAMMER, Role.TESTER, max_turns=10),
    Phase("Documentation", Role.CEO, Role.CPO, max_turns=5),
]
```

### Communicative Dehallucination

LLMの幻覚問題に対し、ChatDevはエージェント間の対話を通じた相互検証を行う。具体的には、コーディングフェーズでProgrammerが生成したコードに対して、テスティングフェーズでTesterが実行・検証し、エラーを指摘する。ProgrammerはTesterの指摘を受けてコードを修正する。この反復的な対話ループにより、単一エージェントでは見逃される幻覚（存在しないAPIの使用、型不整合等）が検出・修正される。

## 実装のポイント（Implementation）

ChatDevの実運用での注意点を整理する。

**コンテキスト長の管理**: フェーズが進行するにつれコンテキストが累積的に増大する。特にCodingフェーズで生成されるコードが大きい場合、後続フェーズでコンテキストウィンドウの上限に達するリスクがある。前段出力の要約やコードの主要部分のみの引き継ぎが有効である。

**ターン数の制御**: max_turnsの設定は品質とコストのトレードオフである。TestingフェーズではバグのFix-Verifyループが必要なため10-15ターンを推奨するが、DesignフェーズやDocumentationフェーズは5ターン程度で十分である。

**役割プロンプトの設計**: Instructor-Assistantの役割は固定的ではなく、フェーズによって同一エージェント（例: CTO）がInstructorにもAssistantにもなる。役割プロンプトにフェーズコンテキストを含めることで、適切な振る舞いを誘導する。

**言語の使い分け**: 設計フェーズは自然言語、コーディングフェーズはプログラミング言語が主体となるが、エラー説明やレビューコメントは自然言語で行うのが効果的である。

## 実験結果（Results）

ChatDevはユーザー要件から実行可能なソフトウェアを自動生成するタスクで評価された。

| 評価指標 | ChatDev | Single Agent | 改善 |
|---------|---------|-------------|------|
| 実行可能率 | 86.66% | 72.33% | +14.33% |
| 平均生成時間 | 7分 | 3分 | -4分 |
| 平均コスト | $0.30未満 | $0.15未満 | +$0.15 |
| コード品質（人間評価） | 3.8/5.0 | 2.9/5.0 | +0.9 |

特筆すべきは、1件あたりのソフトウェア生成コストが$0.30未満という低コストである。Testing Phaseによる反復的な修正が実行可能率の大幅な向上（+14.33%）に貢献している。一方、生成時間は複数フェーズの逐次実行により増加するが、品質向上とのトレードオフとして許容される範囲である。

## 実運用への応用（Practical Applications）

Claude Octopusのようなオーケストレーションプラグインとの関連では、ChatDevのフェーズベースアプローチは有用な設計パターンを提供する。

**並列化の余地**: ChatDevの4フェーズは厳密には逐次依存だが、実際にはDesignフェーズの出力が確定すればCodingとDocumentationの概要生成は並列実行可能である。Claude Octopusの並列実行能力を活用することで、全体のレイテンシを短縮できる。

**スケーリング**: 大規模プロジェクトではモジュール分割を行い、各モジュールに独立したChat Chainを割り当てる分割統治アプローチが有効である。ChatDev 2.0（DevAll）では1000エージェント規模のオーケストレーションをサポートしている。

**品質保証**: Communicative Dehallucinationはコード生成以外のタスク（文書校正、データ分析検証等）にも応用可能である。複数エージェントの相互レビューによる品質向上は汎用的なパターンである。

## 関連研究（Related Work）

- **MetaGPT (Hong et al., 2023)**: SOP（標準作業手順）ベースのマルチエージェント協調。ChatDevがチャットベースの柔軟な対話を採用するのに対し、MetaGPTは構造化された文書（PRD、技術設計書等）を介した情報伝達を重視する
- **AutoGen (Wu et al., 2023)**: 汎用マルチエージェント会話フレームワーク。ChatDevがソフトウェア開発に特化した固定的なフェーズ構造を持つのに対し、AutoGenはタスクに応じた柔軟な会話パターンを提供する
- **CAMEL (Li et al., 2023)**: Instructor-Assistantのロールプレイ対話。ChatDevのフェーズ内対話はCAMELのペア対話を拡張し、フェーズ間の連鎖を追加したものと捉えられる

## まとめと今後の展望

ChatDevはソフトウェア開発プロセス全体をChat Chainとして形式化し、LLMエージェントの協調による自動化を実現した。Instructor-Assistantペアの対話によるフェーズ実行と、Communicative Dehallucinationによる品質保証が主要な技術的貢献である。

今後はChat Chainの動的構成（タスクの難易度に応じたフェーズの追加・省略）、フェーズ間の並列実行最適化、および人間のフィードバックを組み込むHuman-in-the-Loopの強化が研究課題となる。ChatDev 2.0のゼロコードプラットフォーム化は、非エンジニアにもマルチエージェントオーケストレーションを開放する方向性として注目される。

## 参考文献

- **arXiv**: https://arxiv.org/abs/2307.07924
- **Code**: https://github.com/OpenBMB/ChatDev
- **Related Zenn article**: https://zenn.dev/0h_n0/articles/c01f4e292ff1a7
