---
layout: post
title: "論文解説: RAGAS — 参照フリーRAGパイプライン自動評価フレームワーク"
description: "RAGASはground truth不要でFaithfulness・Answer Relevancy・Context Precisionを自動評価するフレームワークです"
categories: [blog, paper, arxiv]
tags: [RAG, RAGAS, evaluation, faithfulness, DeepEval, metrics, EACL]
date: 2026-02-21 10:00:00 +0900
source_type: arxiv
arxiv_id: "2309.15217"
source_url: https://arxiv.org/abs/2309.15217
zenn_article: 32bc8fd091100d
zenn_url: https://zenn.dev/0h_n0/articles/32bc8fd091100d
math: true
mermaid: true
target_audience: "修士学生レベル"
---

## 論文概要（Abstract）

RAGAS（Retrieval Augmented Generation Assessment）は、RAGパイプラインを**人手アノテーションなし**で自動評価するフレームワークです。RAGシステムの品質を「検索品質」と「生成品質」の2軸に分解し、Faithfulness（事実整合性）、Answer Relevancy（回答関連性）、Context Precision（文脈精度）、Context Recall（文脈網羅率）の4指標で測定します。WikiEvalデータセットでの検証において、人間の判断との相関がρ=0.76〜0.83と高く、BLEU/ROUGE/BERTScoreを大幅に上回る評価精度を実現しています。EACL 2024で発表されました。

この記事は [Zenn記事: LangGraph×Claude Sonnet 4.6エージェント型RAGの精度評価と最適化](https://zenn.dev/0h_n0/articles/32bc8fd091100d) の深掘りです。

## 情報源

- **arXiv ID**: 2309.15217
- **URL**: [https://arxiv.org/abs/2309.15217](https://arxiv.org/abs/2309.15217)
- **著者**: Shahul Es, Jithin James, Luis Espinosa-Anke, Steven Schockaert
- **発表年**: 2023
- **分野**: cs.CL
- **会議**: EACL 2024 (Demo Track)

## 背景と動機（Background & Motivation）

RAGシステムの評価は、検索コンポーネントと生成コンポーネントの**相互作用**を考慮する必要があるため、従来手法では不十分でした。人手評価は高精度ですが高コストでスケールしません。BLEU/ROUGE/BERTScoreはテキスト類似度のみを測定し、事実正確性や検索品質を捉えられません。LLMベースの評価（GPT-4 as Judge）は意味論的な評価が可能ですが、プロンプト依存性が高く安定しません。

RAGASのアプローチは、評価タスクを**複数の単純なサブタスク**に分解し、各サブタスクをLLMで独立に解くというものです。この分解戦略により、複合的なRAG品質を原則的かつ再現可能に測定できます。

## 主要な貢献（Key Contributions）

- **参照フリー評価**: Faithfulness、Answer Relevancy、Context Precisionの3指標がground truth不要で計算可能
- **分解ベースの評価戦略**: 回答をステートメント単位に分解し、個々の事実主張を検証する細粒度評価
- **高い人間判断との相関**: Faithfulness r=0.83、Answer Relevancy ρ=0.76、Context Precision r=0.79
- **従来手法の大幅超越**: BLEU (0.21) / ROUGE-L (0.29) / BERTScore (0.32) に対し、Faithfulness相関で0.83を達成

## 技術的詳細（Technical Details）

### 4指標の計算アルゴリズム

RAGASの4指標はそれぞれ独立に計算され、RAGパイプラインの異なる側面を測定します。

#### Faithfulness（事実整合性）

Faithfulnessは、生成された回答が検索文脈と事実的に整合しているかを測定します。ハルシネーション検出に直結する最重要指標です。

**計算手順**:

1. LLMで回答$a$を個別ステートメントの集合$S = \{s_1, s_2, \ldots, s_n\}$に分解
2. 各ステートメント$s_i$について、文脈$c$から推論可能かをLLMで検証
3. Faithfulnessを計算:

$$
F = \frac{|V|}{|S|}
$$

ここで$V \subseteq S$は文脈から推論可能なステートメントの集合です。

**具体例**:

質問: 「フランスの首都は何か？何で有名か？」

文脈: 「パリはフランスの首都で最大の都市。エッフェル塔と世界的な料理で有名。」

回答: 「フランスの首都はパリです。エッフェル塔、ルーブル美術館、優れた料理で有名です。人口は1000万人以上です。」

分解されたステートメント:
- $s_1$: 「フランスの首都はパリ」→ 文脈から推論可能 (True)
- $s_2$: 「エッフェル塔で有名」→ 文脈から推論可能 (True)
- $s_3$: 「ルーブル美術館で有名」→ 文脈に記載なし (False)
- $s_4$: 「優れた料理で有名」→ 文脈から推論可能 (True)
- $s_5$: 「人口は1000万人以上」→ 文脈に記載なし (False)

$$F = \frac{3}{5} = 0.6$$

この分解アプローチにより、回答全体を一括評価するのではなく、**個々の事実主張を独立に検証**できます。

#### Answer Relevancy（回答関連性）

Answer Relevancyは、生成された回答が質問にどれだけ適切に対応しているかを測定します。

**計算手順**:

1. LLMで回答$a$から$n$個の候補質問$\{q_1', q_2', \ldots, q_n'\}$を生成
2. 各候補質問と元の質問$q$のコサイン類似度を文埋め込みで計算
3. Answer Relevancyを計算:

$$
AR = \frac{1}{n} \sum_{i=1}^{n} \text{sim}(q, q_i')
$$

ここで$\text{sim}(q, q')$は文埋め込みのコサイン類似度です。

**直感**: 関連性の高い回答から逆生成される質問は、元の質問と類似するはずです。無関係な情報を含む回答からは、元と異なる質問が生成されます。

アブレーション結果として、$n=3$がコストと精度のバランスが最良です（$n=1$: 0.71、$n=3$: 0.76、$n=5$: 0.77）。

#### Context Precision（文脈精度）

Context Precisionは、検索された文脈チャンクが回答生成に有用かどうか、特に**関連チャンクが上位にランクされているか**を測定します。

$$
CP = \frac{\sum_{k=1}^{K} \text{Precision@}k \cdot \text{rel}_k}{|\text{rel}|}
$$

ここで$K$は検索チャンク総数、$\text{rel}_k$は$k$番目のチャンクの関連性（0 or 1）、$|\text{rel}|$は関連チャンク総数です。これは本質的にmAP（mean Average Precision）と同じ計算で、関連文書が検索結果の上位に位置するほど高いスコアを返します。

#### Context Recall（文脈網羅率）

Context Recallは、正解回答に必要な情報が検索文脈に含まれているかを測定します。**唯一ground truthが必要な指標**です。

$$
CR = \frac{|\text{文脈に帰属できるステートメント数}|}{|\text{正解のステートメント総数}|}
$$

正解回答をステートメントに分解し、各ステートメントが検索文脈に含まれるかをLLMで判定します。

### 実装コード

```python
from ragas import evaluate
from ragas.metrics import (
    faithfulness,
    answer_relevancy,
    context_precision,
    context_recall,
)
from ragas.llms import LangchainLLMWrapper
from langchain_anthropic import ChatAnthropic
from datasets import Dataset

# Claude Sonnet 4.6を評価モデルとして使用
eval_llm = LangchainLLMWrapper(
    ChatAnthropic(model="claude-sonnet-4-6")
)

# 評価データの準備
eval_data = Dataset.from_dict({
    "question": ["Kubernetesのポッド再起動の対処法は？"],
    "answer": ["kubectl describe podでイベントを確認し..."],
    "contexts": [["CrashLoopBackOffはコンテナが起動直後に..."]],
    "ground_truth": ["CrashLoopBackOffの原因調査として..."],
})

# 評価実行（3指標は参照フリー）
results = evaluate(
    dataset=eval_data,
    metrics=[
        faithfulness,
        answer_relevancy,
        context_precision,
        context_recall,  # これのみground truth必要
    ],
    llm=eval_llm,
)

print(results)
# {'faithfulness': 0.87, 'answer_relevancy': 0.91,
#  'context_precision': 0.83, 'context_recall': 0.79}
```

### RAGASとDeepEvalの併用

Zenn記事で紹介されているDeepEvalはpytest互換のフレームワークで、RAGASの指標をDeepEvalのエコシステム内で利用できます。

```python
from deepeval.metrics import RAGASMetric
from deepeval.test_case import LLMTestCase

# DeepEval経由でRAGAS指標を使用
ragas_metric = RAGASMetric(threshold=0.8)

test_case = LLMTestCase(
    input="質問テキスト",
    actual_output="生成された回答",
    retrieval_context=["検索された文書1", "検索された文書2"],
    expected_output="期待される回答",
)

ragas_metric.measure(test_case)
print(f"Score: {ragas_metric.score}")
```

この併用により、RAGASの参照フリー評価をDeepEvalのCI/CD統合と組み合わせ、開発フローに組み込めます。

## 実装のポイント（Implementation）

**LLMの選択が精度に直結**: RAGASの評価精度は使用するLLMに依存します。論文ではGPT-3.5-turboで検証されていますが、Claude Sonnet 4.6のような高性能モデルを使うことで、特にFaithfulnessのステートメント分解精度が向上します。

**ステートメント分解の粒度**: 分解が粗いと評価が不正確になり、細かすぎるとAPI呼び出しコストが増大します。1ステートメント=1事実主張が適切な粒度です。

**Answer Relevancyの候補質問数**: $n=3$が推奨です。$n=1$では相関が0.71に低下し、$n=5$では0.77と微増しますがコストが1.7倍になります。

**Context Precisionのground truth依存**: Context Precisionの関連性判定にはground truthが参照されます。完全に参照フリーにしたい場合はFaithfulnessとAnswer Relevancyの2指標のみを使用してください。

**バッチ処理の最適化**: 50件の評価クエリ × 4指標でのLLM呼び出しは合計約600回になります。レート制限を考慮し、並列度を5-10に設定することを推奨します。

## 実験結果（Results）

WikiEvalデータセット（50問、Wikipedia最近の人物記事ベース）での検証結果は以下の通りです。

| 指標 | Faithfulness相関 | Answer Relevancy相関 | Context Relevance相関 |
|------|-----------------|---------------------|---------------------|
| BLEU | 0.21 | 0.38 | — |
| ROUGE-L | 0.29 | 0.41 | — |
| BERTScore | 0.32 | 0.44 | — |
| **RAGAS** | **0.83** | **0.76** | **0.79** |

RAGASは全次元で従来手法を大幅に上回っています。特にFaithfulness（事実整合性）での相関0.83は、テキスト類似度ベースのBLEU (0.21)の約4倍の精度です。これは、ステートメント分解による細粒度評価が、テキスト表面の類似度では捉えられない事実的正確性を測定できることを示しています。

## 実運用への応用（Practical Applications）

Zenn記事のRAGパイプラインでは、RAGASの4指標を以下のように活用できます。

**CI/CDパイプライン（DeepEval経由）**: PRマージ前にFaithfulness ≥ 0.85、Answer Relevancy ≥ 0.80の品質ゲートを設定。Zenn記事の`test_rag_evaluation.py`がこのパターンです。

**定期バッチ評価（RAGAS直接）**: 週次でContext PrecisionとContext Recallを測定し、検索コンポーネントの劣化を早期検知。新しい文書の追加後は特に重要です。

**障害診断**: 各指標が独立しているため、品質低下時の原因特定が容易です。Faithfulness低下はLLMのハルシネーション、Context Precision低下は検索品質の劣化、Answer Relevancy低下はプロンプトの問題を示唆します。

## 関連研究（Related Work）

- **ARES (2312.10997)**: RAGASと同時期のRAG評価フレームワーク。軽量LM分類器をファインチューニングして評価を行う。RAGASがプロンプトのみで動作するのに対し、ARESは学習データが必要だが、ドメイン特化の評価精度が高い
- **TruLens**: RAGASと類似のLLMベース評価だが、プロンプト戦略が異なる。商用製品として運用ダッシュボードを提供
- **RGB (2309.01431)**: ノイズ堅牢性・否定的拒否・情報統合・反事実的堅牢性の4軸でRAGを評価。RAGASとは異なる評価観点を提供

## まとめと今後の展望

RAGASは、RAG評価を「ステートメント分解」「逆質問生成」「ランキング品質」という原則的なサブタスクに分解することで、参照フリーの自動評価を実現しました。人間判断との高い相関（0.76-0.83）は、実用レベルの自動評価が可能であることを示しています。

今後はマルチターンRAG会話への対応、異なるLLMでの評価安定性の向上、計算コスト削減が課題です。Zenn記事で紹介されているDeepEvalとの併用パターンは、RAGASの強みをCI/CDワークフローに統合する実践的なアプローチとして有効です。

## 参考文献

- **arXiv**: [https://arxiv.org/abs/2309.15217](https://arxiv.org/abs/2309.15217)
- **Code**: [https://github.com/explodinggradients/ragas](https://github.com/explodinggradients/ragas)
- **PyPI**: `pip install ragas`
- **Related Zenn article**: [https://zenn.dev/0h_n0/articles/32bc8fd091100d](https://zenn.dev/0h_n0/articles/32bc8fd091100d)
