---
layout: post
title: "論文解説: A Systematic Review of Reliability Frameworks for Production LLM Systems"
description: "本番LLMシステムの信頼性フレームワークを体系的にレビューし、サーキットブレーカー・フォールバックチェーン・観測性パターンを統合した実践ガイド"
categories: [blog, paper, arxiv]
tags: [LLM, reliability, circuit-breaker, fallback, production, litellm, ai]
date: 2026-02-20 09:00:00 +0900
source_type: arxiv
arxiv_id: "2505.02097"
source_url: https://arxiv.org/abs/2505.02097
zenn_article: f5ba83634a4a9f
zenn_url: https://zenn.dev/0h_n0/articles/f5ba83634a4a9f
math: true
mermaid: true
target_audience: "修士学生レベル"
---

## 論文概要（Abstract）

本論文は、本番グレードのLLMシステムにおける信頼性フレームワークの体系的レビューである。47件の本番事例・グレーリテラチャを統合し、構造化出力バリデーション、サーキットブレーカーとフォールバック機構によるグレースフルデグラデーション、プロンプトエンジニアリング戦略、LLMワークロード向け監視アプローチを包括的に分析している。LLMが従来ソフトウェアと異なる非決定的動作・セマンティック不整合・レイテンシ変動という固有の信頼性課題を持つことを明示し、バリデーションパイプライン・フォールバック戦略・観測性パターンを統合した実践フレームワークを提示する。

この記事は [Zenn記事: LLMフォールバックチェーン設計：3層パターンで高可用性を実現する](https://zenn.dev/0h_n0/articles/f5ba83634a4a9f) の深掘りです。

## 情報源

- **arXiv ID**: 2505.02097
- **URL**: [https://arxiv.org/abs/2505.02097](https://arxiv.org/abs/2505.02097)
- **著者**: Shubham Kulkarni
- **発表年**: 2025
- **分野**: cs.SE, cs.AI, cs.LG

## 背景と動機（Background & Motivation）

従来のソフトウェアシステムは決定的に動作する。データベースクエリやREST APIコールは成功か失敗かの二値で結果が返る。しかしLLMは本質的に確率的であり、障害がスペクトラム上で発生する。構造的に正しいJSONでもセマンティックに不正確、文法的に正しくても事実として誤り、APIレスポンスコードは正常でも出力が壊れているといった「ソフト障害」が頻発する。

主要LLMプロバイダの障害実績分析では、OpenAI GPT-4が年間4-6回（平均45分）、Anthropic Claudeが2-3回（平均30分）、Google Geminiが3-5回（平均60分）の重大障害が報告されており、単一プロバイダ依存では年間2-8時間のダウンタイムリスクが生じる。この現実が、マルチプロバイダフォールバックの設計を必須にしている。

## 主要な貢献（Key Contributions）

- **LLM固有の障害分類体系**: ハード障害（HTTP 429/503等）・ソフト障害（ハルシネーション・フォーマット違反）・劣化レスポンス（切り詰め・反復・高レイテンシ）の3分類を定義
- **6段階フォールバック階層**: 同一プロバイダリトライ→パラメータ緩和→モデルダウングレード→プロバイダフェイルオーバー→ローカルモデル→グレースフルデグラデーションの段階的エスカレーション設計
- **LLM拡張サーキットブレーカー**: ソフト障害（品質劣化）も追跡する拡張版Closed/Open/Half-Open状態機械
- **ツール比較マトリクス**: LiteLLM・PortKey・Helicone・Langchain・LlamaIndexの機能比較

## 技術的詳細（Technical Details）

### LLM固有の障害分類

従来のHTTPステータスコードベースの障害検知だけでは、LLMシステムの信頼性は確保できない。本論文は障害を以下の3層に分類する。

| 障害カテゴリ | 具体例 | 検知方法 |
|-------------|--------|---------|
| **ハード障害** | API タイムアウト、HTTP 429（レートリミット）、HTTP 503（サービス不能）、コンテキスト長超過 | HTTPステータスコード、例外ハンドリング |
| **ソフト障害** | ハルシネーション、フォーマット非準拠、指示非遵守、有害出力 | バリデーションパイプライン、品質スコアリング |
| **劣化レスポンス** | 出力切り詰め、反復コンテンツ、P95レイテンシ>10秒 | メトリクス監視、しきい値アラート |

この分類が重要なのは、ハード障害のみを扱う従来のサーキットブレーカーでは、品質が静かに劣化する「サイレントデグラデーション」を検知できないためである。

### LLM拡張サーキットブレーカー

分散システム工学のサーキットブレーカーパターン（Nygard, 2007）をLLM向けに拡張する。標準的な3状態（Closed/Open/Half-Open）に加え、以下の3つの拡張が必要である。

**拡張1: ソフト障害追跡**

ハード障害（例外）の重み$w_h = 1.0$に対し、ソフト障害（品質劣化）の重み$w_s = 0.5$として加重障害率を計算する。

$$
\text{failure\_rate} = \frac{\sum_{i \in W} w_i \cdot \mathbb{1}[\text{failed}_i]}{|W|}
$$

ここで、$W$はスライディングウィンドウ内のコール集合、$w_i$は障害種別に応じた重み、$\mathbb{1}[\text{failed}_i]$は障害発生の指示関数である。

**拡張2: レイテンシベーストリッピング**

P95レイテンシがP50ベースラインの3倍を超えた場合、エラー率に関わらずサーキットを開放する。

$$
\text{trip\_condition} = \text{latency}_{P95} > 3 \times \text{latency}_{P50\_baseline}
$$

**拡張3: プロバイダ別独立状態**

各LLMプロバイダ（OpenAI、Anthropic、Cohere、ローカルモデル等）が独立したサーキットブレーカー状態を持つ。これにより、オーケストレーション層が劣化プロバイダを迂回してルーティングできる。

```python
from enum import Enum
from datetime import datetime, timedelta
from collections import deque
from typing import Optional, Callable, Any

class CircuitState(Enum):
    CLOSED = "closed"
    OPEN = "open"
    HALF_OPEN = "half_open"

class LLMCircuitBreaker:
    """LLM API呼び出し向け拡張サーキットブレーカー。
    ハード障害（例外）とソフト障害（品質メトリクス）の両方を追跡する。

    Args:
        failure_threshold: ウィンドウ内の障害数しきい値
        success_threshold: Half-OpenからClosedへの復帰に必要な成功数
        timeout: Open状態の持続時間（秒）
        window_size: スライディングウィンドウサイズ
        quality_threshold: 品質スコアの最低しきい値（0-1）
    """

    def __init__(
        self,
        failure_threshold: int = 5,
        success_threshold: int = 2,
        timeout: float = 60.0,
        window_size: int = 10,
        quality_threshold: float = 0.7,
    ):
        self.failure_threshold = failure_threshold
        self.success_threshold = success_threshold
        self.timeout = timeout
        self.window_size = window_size
        self.quality_threshold = quality_threshold

        self.state = CircuitState.CLOSED
        self.failure_count = 0
        self.success_count = 0
        self.last_failure_time: Optional[datetime] = None
        self.recent_calls: deque = deque(maxlen=window_size)

    def _calculate_failure_rate(self) -> float:
        """加重障害率を計算。ソフト障害は0.5、ハード障害は1.0"""
        if not self.recent_calls:
            return 0.0
        weighted_failures = sum(
            0.5 if call.get("soft") else 1.0
            for call in self.recent_calls
            if not call["success"]
        )
        return weighted_failures / len(self.recent_calls)

    async def call(
        self,
        func: Callable,
        *args: Any,
        quality_check: Optional[Callable] = None,
        **kwargs: Any,
    ) -> Any:
        """サーキットブレーカー経由でLLM呼び出しを実行"""
        if self.state == CircuitState.OPEN:
            if (datetime.now() - self.last_failure_time
                    > timedelta(seconds=self.timeout)):
                self.state = CircuitState.HALF_OPEN
                self.success_count = 0
            else:
                raise CircuitOpenError(
                    f"Circuit OPEN. Retry after {self.timeout}s"
                )

        try:
            result = await func(*args, **kwargs)
            is_quality_pass = True
            if quality_check is not None:
                quality_score = quality_check(result)
                is_quality_pass = quality_score >= self.quality_threshold

            if is_quality_pass:
                self._record_success()
            else:
                self._record_failure(soft=True)
            return result
        except Exception:
            self._record_failure(soft=False)
            raise
```

### 6段階フォールバック階層

論文が提示する6段階のフォールバック階層は、Zenn記事で紹介した3層パターン（リトライ→フォールバック→サーキットブレーカー）をさらに細分化したものである。

| Tier | 戦略 | 対象障害 | レイテンシ増加 |
|------|------|---------|--------------|
| 1 | 同一プロバイダリトライ | 一時的エラー（429, 503） | +1-4秒 |
| 2 | パラメータ緩和 | コンテキスト長超過、レートリミット | +2-5秒 |
| 3 | モデルダウングレード | プロバイダ内の品質・コスト調整 | ≈同等 |
| 4 | プロバイダフェイルオーバー | プロバイダ障害 | +0.5-2秒 |
| 5 | ローカルモデルフォールバック | 外部API依存排除 | 変動 |
| 6 | グレースフルデグラデーション | 全プロバイダ障害 | 0秒（キャッシュ） |

Tier 2（パラメータ緩和）はZenn記事では明示していないが、実務上重要なテクニックである。`temperature`を下げる、`max_tokens`を短縮する、システムプロンプトを簡素化するといった調整で、同一プロバイダ内でリソース消費を減らしながらリトライできる。

### リトライ設定の推奨値

```python
RETRY_CONFIGS: dict[int, dict] = {
    429: {"retry": True, "max_attempts": 5,
          "strategy": "exponential+retry-after"},
    500: {"retry": True, "max_attempts": 3,
          "strategy": "exponential(1s,2s,4s)+jitter"},
    503: {"retry": True, "max_attempts": 3,
          "strategy": "exponential(1s,2s,4s)+jitter"},
    408: {"retry": True, "max_attempts": 2,
          "strategy": "linear(2s,2s)"},
    400: {"retry": False, "action": "immediate_fallback"},
    401: {"retry": False, "action": "alert+circuit_open"},
    403: {"retry": False, "action": "alert+circuit_open"},
}

TIMEOUT_CONFIGS: dict[str, tuple[float, float]] = {
    # (connect_timeout, read_timeout) seconds
    "claude-sonnet-4-6":   (5.0, 120.0),
    "claude-haiku-4-5":    (5.0,  60.0),
    "gpt-4.1":             (5.0, 120.0),
    "gpt-4.1-mini":        (5.0,  60.0),
    "gemini-2.5-pro":      (5.0,  90.0),
    "ollama-local":        (2.0, 300.0),
}
```

HTTP 400（Bad Request）やHTTP 401/403（認証エラー）はリトライしても回復しないため、即座にフォールバックまたはアラートに遷移する。これはZenn記事で述べた「一時的障害にプロバイダ切替すると不要なコスト増が発生する」原則と整合する。

## 実装のポイント（Implementation）

### フォールバックチェーンの構築

```python
from dataclasses import dataclass
from typing import List, Optional, Callable, Any

@dataclass
class FallbackProvider:
    """フォールバックチェーン内の1プロバイダを表現"""
    name: str
    call_fn: Callable
    priority: int
    circuit_breaker: LLMCircuitBreaker
    max_retries: int = 3
    base_delay: float = 1.0
    cost_per_1k_tokens: float = 0.0

class FallbackChain:
    """優先順位付きLLMプロバイダチェーンを管理"""

    def __init__(
        self,
        providers: List[FallbackProvider],
        quality_check: Optional[Callable[[Any], float]] = None,
    ):
        self.providers = sorted(providers, key=lambda p: p.priority)
        self.quality_check = quality_check

    async def execute(self, prompt: str, **kwargs: Any) -> tuple[Any, str]:
        """(response, provider_name) を返す"""
        last_exception = None
        for provider in self.providers:
            if provider.circuit_breaker.state == CircuitState.OPEN:
                continue
            for attempt in range(provider.max_retries):
                try:
                    response = await provider.circuit_breaker.call(
                        provider.call_fn,
                        prompt,
                        quality_check=self.quality_check,
                        **kwargs,
                    )
                    return response, provider.name
                except CircuitOpenError:
                    break
                except Exception as e:
                    last_exception = e
                    delay = provider.base_delay * (2 ** attempt)
                    await asyncio.sleep(delay)
        raise AllProvidersExhaustedError(
            f"All providers exhausted: {last_exception}"
        )
```

### プロバイダ間プロンプト適応

プロバイダフェイルオーバー時の最大の摩擦は「プロンプトのポータビリティ」である。論文は3つの戦略を提示する。

1. **プロバイダ非依存プロンプト**: 全プロバイダで動作するが、個別プロバイダでの最適性は犠牲にする。ほとんどのユースケースで推奨
2. **プロンプトテンプレートライブラリ**: プロバイダ別のプロンプト変種を管理。保守コストが高いが個別性能は向上
3. **動的プロンプト適応**: 軽量分類器で実行時にプロンプトを変換。新興アプローチで本番実績は限定的

### 既存ツール比較

| ツール | サーキットブレーカー | フォールバックチェーン | コスト追跡 | OSS |
|--------|-------------------|---------------------|-----------|-----|
| **LiteLLM** | 部分的（クールダウン） | ✅ | ✅ | MIT |
| **PortKey.ai** | ✅ | ✅ | ✅ | ❌ |
| **Helicone** | ❌ | ❌ | ✅ | 部分的 |
| **Langchain** | 手動実装 | 部分的 | ❌ | MIT |
| **LlamaIndex** | 手動実装 | 部分的 | ❌ | MIT |

LiteLLMが実務上の出発点として最も推奨されている。Zenn記事で紹介した`allowed_fails`と`cooldown_time`による簡易サーキットブレーカーは、LiteLLMの「部分的」対応に該当する。Half-Open状態での段階的復旧が必要な場合は、本論文の`LLMCircuitBreaker`クラスのようなカスタム実装が必要になる。

## 実験結果（Results）

本論文は47件の本番事例・グレーリテラチャの定性分析であり、ベンチマーク実験は含まない。代わりに、プロバイダ障害の実績データを提示している。

| プロバイダ | 年間重大障害回数 | 平均障害時間 | 推定年間ダウンタイム |
|-----------|----------------|------------|------------------|
| OpenAI GPT-4 | 4-6回 | 45分 | 3-4.5時間 |
| Anthropic Claude | 2-3回 | 30分 | 1-1.5時間 |
| Google Gemini | 3-5回 | 60分 | 3-5時間 |

単一プロバイダ依存の場合、年間2-8時間のダウンタイムが見込まれる。マルチプロバイダフォールバック+サーキットブレーカー構成では、大半の事例でダウンタイムが15分未満に短縮されたと報告されている。

## 実運用への応用（Practical Applications）

Zenn記事で紹介した3層パターン（リトライ→フォールバック→サーキットブレーカー）は、本論文の6段階フォールバック階層のTier 1, 4, 3（順序変更）に対応する。本論文を参考にすることで、以下の拡張が可能になる。

1. **Tier 2（パラメータ緩和）の追加**: コンテキスト長超過時に`max_tokens`を短縮してリトライ。LiteLLMの設定では直接サポートされないが、カスタムミドルウェアで実装可能
2. **ソフト障害追跡の導入**: LiteLLMの`cooldown`はハード障害のみカウントする。品質スコアリング関数を追加し、スコア低下時もクールダウン対象に含める
3. **観測性スキーマの標準化**: `fallback_from`, `circuit_state`, `quality_score`フィールドを構造化ログに追加し、サイレントデグラデーションを検知可能にする

## 観測性パターン（Observability）

### 必須メトリクス

本論文が定義する4カテゴリのメトリクスは、フォールバックチェーンの健全性監視に不可欠である。

**可用性メトリクス**:
- `llm.request.success_rate` — プロバイダ・モデル・リクエストタイプ別
- `llm.circuit_breaker.state` — プロバイダ別（0=closed, 1=half-open, 2=open）
- `llm.fallback.rate` — 非プライマリプロバイダへのフォールスルー率

**品質メトリクス**:
- `llm.response.format_compliance_rate` — 構造バリデーション通過率
- `llm.response.quality_score` — アプリケーション固有品質（0-1）

### 構造化ログスキーマ

```json
{
  "event": "llm_request_complete",
  "level": "INFO",
  "ts": "2026-02-20T09:00:00.000Z",
  "request_id": "req_abc123",
  "provider": "anthropic",
  "model": "claude-sonnet-4-6",
  "attempt": 1,
  "fallback_from": null,
  "duration_ms": 2341,
  "ttft_ms": 412,
  "input_tokens": 1024,
  "output_tokens": 256,
  "cost_usd": 0.00384,
  "circuit_state": "closed",
  "quality_score": 0.92,
  "format_valid": true
}
```

`fallback_from`フィールドが`null`でない場合、フォールバックが発動したことを示す。これにより、フォールバック発動率を正確に計算し、Zenn記事で述べた「5%超過で警告、10%超過で緊急アラート」のしきい値監視が可能になる。

## 関連研究（Related Work）

- **Nygard (2007)**: 「Release It!」で分散システム向けサーキットブレーカーパターンを提唱。本論文はこれをLLM向けに拡張し、ソフト障害追跡とレイテンシベーストリッピングを追加
- **RouteLLM (Ong et al., 2024)**: コスト最適化ルーティングフレームワーク。品質-コストのトレードオフを最適化するが、可用性フォールバックは非対応。本論文のフォールバックチェーンと組み合わせて使用可能
- **LiteLLM**: OSS（MITライセンス）のマルチプロバイダプロキシ。本論文ではLiteLLMを「プラグマティックな出発点」として位置づけつつ、そのサーキットブレーカー（クールダウン方式）の限界を指摘

## まとめと今後の展望

本論文は、LLMシステムの信頼性を「バリデーション→フォールバック→観測性」の3層で捉え、47件の本番事例から実践的なフレームワークを構築した。Zenn記事で紹介した3層パターンの理論的裏付けと拡張方向を提供する重要な1次情報である。

今後の研究方向としては、（1）LLMルーティングと可用性フォールバックの統合、（2）品質スコアリングの標準化、（3）マルチプロバイダ環境でのプロンプトポータビリティの自動化が挙げられている。

## 参考文献

- **arXiv**: [https://arxiv.org/abs/2505.02097](https://arxiv.org/abs/2505.02097)
- **Related Zenn article**: [https://zenn.dev/0h_n0/articles/f5ba83634a4a9f](https://zenn.dev/0h_n0/articles/f5ba83634a4a9f)
- **LiteLLM Documentation**: [https://docs.litellm.ai/docs/proxy/reliability](https://docs.litellm.ai/docs/proxy/reliability)
- **RouteLLM**: [https://github.com/lm-sys/RouteLLM](https://github.com/lm-sys/RouteLLM)

---

:::message
この記事はAI（Claude Code）により自動生成されました。内容の正確性については複数の情報源で検証していますが、実際の利用時は公式ドキュメントもご確認ください。
:::
