---
layout: post
title: "サーベイ解説: Agentic RAG — エージェント型検索拡張生成の体系的分類と設計パターン"
description: "Naive RAGからAgentic RAGへの進化を4段階で体系化し、Single/Multi/Hierarchical Agentの3アーキテクチャパターンを解説するサーベイ論文"
categories: [blog, paper, arxiv]
tags: [RAG, agentic-ai, multi-agent, LLM, langgraph, python]
date: 2026-02-22 09:00:00 +0900
source_type: arxiv
arxiv_id: "2501.15228"
source_url: https://arxiv.org/abs/2501.15228
zenn_article: a4cd3a7f1cf4ce
zenn_url: https://zenn.dev/0h_n0/articles/a4cd3a7f1cf4ce
math: true
mermaid: true
target_audience: "修士学生レベル"
---

## 論文概要（Abstract）

Agentic Retrieval-Augmented Generation（Agentic RAG）は、従来のRAGパイプラインに自律的AIエージェントを統合するパラダイムです。本サーベイ（Singh et al., 2025）は、Naive RAGからAdvanced RAG、Modular RAG、そしてAgentic RAGへの進化を4段階で体系化し、反復的な検索精錬・戦略的計画・適応的マルチステップ検索が可能なシステムの設計原則とアーキテクチャパターンを網羅的に整理しています。

この記事は [Zenn記事: LangGraph×Claude Sonnet 4.6で実装する階層的Agentic RAG検索パイプライン](https://zenn.dev/0h_n0/articles/a4cd3a7f1cf4ce) の深掘りです。

## 情報源

- **arXiv ID**: 2501.15228
- **URL**: [https://arxiv.org/abs/2501.15228](https://arxiv.org/abs/2501.15228)
- **著者**: Aditi Singh, Abul Ehtesham, Saket Kumar, Tala Talaei Khoei
- **発表年**: 2025
- **分野**: cs.AI, cs.LG, cs.NE

## 背景と動機（Background & Motivation）

大規模言語モデル（LLM）は高い言語理解・生成能力を持つ一方、学習データの知識カットオフ、コンテキストウィンドウの制約、ハルシネーションという根本的な課題を抱えています。Retrieval-Augmented Generation（RAG）はこれらの課題に対して、外部知識を動的に取得することで対応しますが、従来のRAGは「1回の検索→1回の生成」という固定的なパイプラインに限定されていました。

複雑なマルチホップ質問や、リアルタイム情報が必要なタスクでは、この単純なパイプラインでは不十分です。**Agentic RAG**は、RAGをエージェントのツールの一つとして組み込み、自律的に検索計画を立て、結果を評価し、必要に応じて再検索する仕組みを実現します。

本サーベイは、この進化の全体像を初めて体系的に整理した論文として重要です。

## 主要な貢献（Key Contributions）

- **貢献1**: RAGの進化を**Naive → Advanced → Modular → Agentic**の4段階で体系化した初の包括的分類体系
- **貢献2**: Agentic RAGの3つのアーキテクチャパターン（**Single-Agent / Multi-Agent / Hierarchical Multi-Agent**）を定義し、各パターンの適用条件を明確化
- **貢献3**: メモリ種別（短期・長期・作業記憶）と計画メカニズム（ReAct / CoT / MCTS）を横断的に整理し、設計指針を提示

## 技術的詳細（Technical Details）

### RAG進化の4段階

本サーベイが提案する分類体系の核心は、RAGシステムの進化を4段階で捉えることです。

**Stage 1: Naive RAG**

最も基本的な構成で、「検索→生成」の単一パスを実行します。

$$
a = \text{LLM}(q \oplus \text{Retrieve}(q, \mathcal{D}))
$$

ここで、$q$はクエリ、$\mathcal{D}$はドキュメントコーパス、$\oplus$はコンテキスト結合を表します。シンプルだが、検索品質が低い場合にノイズが生成品質を劣化させます。

**Stage 2: Advanced RAG**

検索前処理（クエリ拡張、HyDE）と検索後処理（リランキング、コンテキスト圧縮）を追加します。

$$
a = \text{LLM}(q \oplus \text{Rerank}(\text{Retrieve}(\text{Expand}(q), \mathcal{D})))
$$

検索品質は改善されますが、固定的なパイプラインのため柔軟性に欠けます。

**Stage 3: Modular RAG**

検索・リランキング・生成をモジュール化し、パイプラインの各段階を交換可能にします。LangChainやLlamaIndexが代表的なフレームワークです。

**Stage 4: Agentic RAG**

エージェントループを導入し、**Plan → Retrieve → Reflect → Refine → Answer**のサイクルを実現します。

```
Plan → Retrieve → Reflect → Refine → Answer
 ↑                              |
 └──────── Feedback ←───────────┘
```

このループにより、検索結果が不十分な場合にクエリを書き換えて再検索したり、複数のツール（Web検索、コード実行、構造化DB）を組み合わせたりすることが可能になります。

### Agentic RAGの3アーキテクチャパターン

**パターン1: Single-Agent RAG**

1つのエージェントが検索・推論・生成を統合的に管理します。

代表手法:
- **ReAct-RAG**: 推論（Reasoning）と行動（Acting）を交互に実行
- **Self-RAG**: 検索の必要性を自己判断し、結果を自己批評
- **Adaptive-RAG**: クエリ複雑度に応じて検索戦略を切り替え

Zenn記事で紹介されている階層的検索パイプラインは、このSingle-Agentパターンの発展形に位置づけられます。1つのエージェント（Claude Sonnet 4.6）が`keyword_search` / `semantic_search` / `chunk_read`の3ツールを使い分けます。

**パターン2: Multi-Agent RAG**

専門化されたエージェントが協調動作します。

| エージェント | 役割 |
|-------------|------|
| **Router Agent** | クエリを適切な検索ソースにルーティング |
| **Retrieval Agent** | Dense/Sparse/KBベースの検索を実行 |
| **Reasoning Agent** | 取得した証拠を統合して推論 |
| **Critic Agent** | 回答品質を評価し、必要に応じて再検索を指示 |

この構成は、LangGraphの`StateGraph`でノードとエッジとして自然に表現できます。

**パターン3: Hierarchical Multi-Agent RAG**

親エージェントがタスクを分解し、子エージェントに割り当て、結果を集約します。大規模ドキュメントコーパスを扱うエンタープライズRAGに適しています。

$$
a = \text{Parent}(\text{Aggregate}(\text{Child}_1(q_1), \text{Child}_2(q_2), \ldots, \text{Child}_n(q_n)))
$$

### エージェントメモリの3分類

| メモリ種別 | 内容 | 実装例 |
|-----------|------|--------|
| **Short-term** | インコンテキストの検索結果 | LangGraphの`State`に格納 |
| **Long-term** | ベクトルストアのエピソード記憶 | FAISS / Chroma / Pinecone |
| **Working Memory** | 中間推論チェーン | LangGraphの`search_history` |

Zenn記事の`search_history`と`visited_chunks`は、まさにWorking Memoryの実装例です。これらがないと、エージェントが同じチャンクを何度も読み直し、トークン消費が爆増するとA-RAG論文でも指摘されています。

### 計画メカニズム

サーベイは3つの主要な計画メカニズムを特定しています。

- **ReAct**: 推論ステップと行動ステップを交互に実行。最も広く使われている。
- **Chain-of-Thought before Retrieval**: 検索前に推論チェーンを生成し、検索クエリの質を向上。
- **Monte Carlo Tree Search (MCTS)**: 推論パスを探索木として表現し、UCBポリシーで最適パスを探索。最新のMCTS-RAG（Hu et al., 2025）がこのアプローチの代表例。

## 実装のポイント（Implementation）

本サーベイの知見をLangGraphで実装する際の重要なポイントをまとめます。

### 検索戦略の選択

| 検索手法 | 実装例 | 適するクエリ |
|---------|--------|------------|
| **Dense Retrieval** | FAISS + `text-embedding-3-small` | 概念的な類似性検索 |
| **Sparse Retrieval** | BM25 / TF-IDF | キーワード完全一致検索 |
| **Hybrid** | RRF（Reciprocal Rank Fusion） | 両方の長所を組み合わせ |
| **Graph-based** | Neo4j / Knowledge Graph | 構造化された関係性の検索 |

Zenn記事の`keyword_search`（Sparse）と`semantic_search`（Dense）の組み合わせは、Hybridアプローチの一形態です。

### エージェントループの安全弁

サーベイが明確に指摘する重要な課題は、**エージェントループのスタック問題**です。検索ループが無限に続く、あるいは非一貫な検索戦略を生成する可能性があります。

```python
# Zenn記事のiteration_countによる安全弁は、
# サーベイが推奨するベストプラクティスの実装例
MAX_ITERATIONS = 5

def should_continue(state: MainState) -> str:
    if state.get("iteration_count", 0) >= MAX_ITERATIONS:
        return "force_answer"  # 強制回答
    if has_tool_calls(state):
        return "tools"
    return "end"
```

### スケーラビリティの課題

サーベイは、反復検索のレイテンシが検索ラウンド数の2乗で増加する可能性を指摘しています。

$$
\text{Latency} \propto n^2 \cdot t_{\text{retrieval}}
$$

ここで$n$は検索ラウンド数、$t_{\text{retrieval}}$は1回の検索レイテンシです。Zenn記事のクエリ複雑度ルーター（Haiku 4.5で分類）は、この問題に対する実用的な解決策です。単純なクエリには不要な反復検索を省略できます。

## 実験結果（Results）

本サーベイ自体はベンチマーク実験を行っていませんが、引用論文群のベンチマーク結果を集約しています。

| 手法 | HotpotQA | PopQA | MuSiQue | パターン |
|------|----------|-------|---------|---------|
| Naive RAG | ~67% | ~48% | ~38% | Stage 1 |
| Self-RAG | ~70% | ~52% | ~41% | Stage 4 (Single) |
| Adaptive-RAG | ~72% | ~54% | ~43% | Stage 4 (Single) |
| CoRAG | **~86%** | **~74%** | **~55%** | Stage 4 (Single) |
| A-RAG | **94.5%** | - | - | Stage 4 (Single) |

Stage 4（Agentic RAG）の手法群が、Stage 1（Naive RAG）に対して一貫した改善を示しています。特にマルチホップQAタスク（HotpotQA、MuSiQue）での改善が顕著です。

## 実運用への応用（Practical Applications）

サーベイは以下の5つの応用領域を特定しています。

1. **エンタープライズ知識管理**: 社内文書検索（Hierarchical Multi-Agent RAGが最適）
2. **医療文献検索**: 正確性と根拠の追跡が必須な領域
3. **法律文書分析**: 判例と法令の横断検索
4. **コード生成**: ドキュメント検索を伴うコーディングアシスタント
5. **科学文献統合**: 複数論文の知見を統合するリサーチアシスタント

Zenn記事のユースケース（社内検索の回答精度改善）は、1番目のエンタープライズ知識管理に直接対応します。Hierarchical Multi-Agent構成を採用する場合、LangGraphのサブグラフ機能で親エージェントと子エージェントを自然に分離できます。

## 関連研究（Related Work）

- **ReAct** (Yao et al., 2022): 推論と行動の交互実行。Agentic RAGの基盤となるパラダイム。
- **Self-RAG** (Asai et al., 2023): 検索の必要性を自己判断する反省トークンの導入。Single-Agent RAGの代表的手法。
- **IRCoT** (Trivedi et al., 2022): 検索とChain-of-Thought推論のインターリービング。Agentic RAGの先駆的手法。
- **Lewis et al. (2020)**: RAGの原論文。Stage 1（Naive RAG）の定義。

## まとめと今後の展望

本サーベイは、RAGの進化を4段階で体系化し、Agentic RAGの設計パターンを明確に分類した重要な貢献です。Zenn記事で実装した階層的検索パイプラインは、Single-Agent RAG（Stage 4）の発展形として位置づけられ、A-RAG論文の3層検索ツール設計と整合しています。

今後の研究方向として、標準的なAgentic RAG評価ベンチマークの策定、効率的なマルチエージェント協調プロトコルの開発、検索拡張型推論モデル（RAGとChain-of-Thought学習の統合）が挙げられています。

## 参考文献

- **arXiv**: [https://arxiv.org/abs/2501.15228](https://arxiv.org/abs/2501.15228)
- **Related Zenn article**: [https://zenn.dev/0h_n0/articles/a4cd3a7f1cf4ce](https://zenn.dev/0h_n0/articles/a4cd3a7f1cf4ce)
- **Yao et al. (2022)**: ReAct: Synergizing Reasoning and Acting in Language Models
- **Asai et al. (2023)**: Self-RAG: Learning to Retrieve, Generate, and Critique Through Self-Reflection
- **Trivedi et al. (2022)**: Interleaving Retrieval with Chain-of-Thought Reasoning
- **Lewis et al. (2020)**: Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks
